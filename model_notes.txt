# From the NVLabs code
OPS = OrderedDict([
    ('res_elu', lambda Cin, Cout, stride: ELUConv(Cin, Cout, 3, stride, 1)),
    ('res_bnelu', lambda Cin, Cout, stride: BNELUConv(Cin, Cout, 3, stride, 1)),
    ('res_bnswish', lambda Cin, Cout, stride: BNSwishConv(Cin, Cout, 3, stride, 1)),
    ('res_bnswish5', lambda Cin, Cout, stride: BNSwishConv(Cin, Cout, 3, stride, 2, 2)),
    ('mconv_e6k5g0', lambda Cin, Cout, stride: InvertedResidual(Cin, Cout, stride, ex=6, dil=1, k=5, g=0)),
    ('mconv_e3k5g0', lambda Cin, Cout, stride: InvertedResidual(Cin, Cout, stride, ex=3, dil=1, k=5, g=0)),
    ('mconv_e3k5g8', lambda Cin, Cout, stride: InvertedResidual(Cin, Cout, stride, ex=3, dil=1, k=5, g=8)),
    ('mconv_e6k11g0', lambda Cin, Cout, stride: InvertedResidual(Cin, Cout, stride, ex=6, dil=1, k=11, g=0)),
])

# The default architecture string in the NVLabs code is 'res_mbconv'
elif arch_type == 'res_mbconv':
    arch_cells = dict()
    arch_cells['normal_enc'] = ['res_bnswish', 'res_bnswish']
    arch_cells['down_enc'] = ['res_bnswish', 'res_bnswish']
    arch_cells['normal_dec'] = ['mconv_e6k5g0']
    arch_cells['up_dec'] = ['mconv_e6k5g0']
    arch_cells['normal_pre'] = ['res_bnswish', 'res_bnswish']
    arch_cells['down_pre'] = ['res_bnswish', 'res_bnswish']
    arch_cells['normal_post'] = ['mconv_e3k5g0']
    arch_cells['up_post'] = ['mconv_e3k5g0']
    arch_cells['ar_nn'] = ['']
        


Base Conv2D -> [weight_norm, std.conv2d]

# All batch_norms use momentum=0.95 (or 1-0.95=0.05 if in Torch)
(DECODER) ConvBNSwish -> [Conv2D(bias=False, weight_norm=False), batch_norm, swish]
(ENCODER) BNSwishConv -> [batch_norm, swish, Conv2D(bias=True, weight_norm=True)]

EncCombinerCell(x1,x2) -> x1 + Conv2d_1x1(x2)
DecCombinerCell(x1,x2) -> Conv2d_1x1(x1 concat x2)

SqueezeExcite -- Standard, use max(c//16, 4) for the squeeze part

# This is used only on the DECODER side
InvertedResidual ->
    hidden_dim = int(round(Cin * ex))

    layers0 = [] if self.upsample else []
    layers = [
        nn.UpsamplingNearest2d(scale_factor=2) if upsample else Identity(),
        get_batchnorm(Cin, eps=BN_EPS, momentum=0.05),
	ConvBNSwish(Cin, hidden_dim, k=1),
	ConvBNSwish(hidden_dim, hidden_dim, stride=self.stride, groups=groups, k=k, dilation=dil),
	Conv2D(hidden_dim, Cout, 1, 1, 0, bias=False, weight_norm=False),
	get_batchnorm(Cout, momentum=0.05)
    ]

# Transforms the original number of channels to the base num channels
Stem -> Conv2d_3x3  (channels=3 -> num_channels_enc)

# ENCODER - Preproc and Residual Cells
Cell(res_bnswish*2) -> [store_skip_conn, BNSwishConv(3x3, stride), BNSwishConv(3x3, stride), squeeze_excite]
    normal_enc (strides=1)
    normal_pre (strides=1)
    down_enc   (strides=2)
    down_pre   (strides=2)

# DECODER - Residual Cells
Cell(mconv_e6k5g0) -> [store_skip_conn, InvertedResidual(ex=6, k=5, g=0), squeeze_excite]
    normal_dec (strides=1)
    up_dec     (strides=-1)

# DECODER - Postproc Cells
Cell(mconv_e3k5g0) -> [store_skip_conn, InvertedResidual(ex=3, k=5, g=0), squeeze_excite]
    normal_post (strides=1)
    up_post     (strides=-1)
    



Assume params:
   num_scales = 2
   num_groups_per_scale = 2
   num_cells_per_group = 3

   preproc_blocks = 2
   preproc_cells = 3

   postproc_blocks = 2
   postproc_cells = 3



stem:
    Conv2d_3x3(cin=3, cout=num_channels_enc)
    
pre_process:
    block0
        Cell(res_bnswish*2)            (normal_pre)
        Cell(res_bnswish*2)            (normal_pre)
        Cell(res_bnswish*2, strides=2) (down_pre)
    block1
        Cell(res_bnswish*2)            (normal_pre)
        Cell(res_bnswish*2)            (normal_pre)
        Cell(res_bnswish*2, strides=2) (down_pre)
        
encoder_tower:
    scale0 g0 
        Cell(res_bnswish*2)
        Cell(res_bnswish*2)
        Cell(res_bnswish*2)
                Cell(combiner_enc)
    scale0 g1
        Cell(res_bnswish*2)
        Cell(res_bnswish*2)
        Cell(res_bnswish*2)
                Cell(combiner_enc)

        Cell(res_bnswish*2, strides=2)
        
    scale1 g0 
        Cell(res_bnswish*2)
        Cell(res_bnswish*2)
        Cell(res_bnswish*2)
                Cell(combiner_enc)
    scale1 g1
        Cell(res_bnswish*2)
        Cell(res_bnswish*2)
        Cell(res_bnswish*2)
                Cell(combiner_enc)

        #Cell(res_bnswish*2, strides=2) # omit on the last scale

encoder0
    ELU(s)
    Conv2D(N, N, 1x1, bias=True)(s)
    ELU(s)

normal_sampler
    encoder_sampler:
        scale0 g0 Conv2D(_, 2*latent_per_group, 3x3)
        scale0 g1 Conv2D(_, 2*latent_per_group, 3x3)
        mult = mult / CHANNEL_MULT
        scale1 g0 Conv2D(_, 2*latent_per_group, 3x3)
        scale1 g1 Conv2D(_, 2*latent_per_group, 3x3)

    decoder_sampler:
        scale0 g0         # scale,group = 0,0 omits first decoder Conv)
        scale0 g1 [ELU, Conv2D(_, 2*latent_per_group, 1x1)]
        mult = mult / CHANNEL_MULT
        scale1 g0 [ELU, Conv2D(_, 2*latent_per_group, 1x1)]
        scale1 g1 [ELU, Conv2D(_, 2*latent_per_group, 1x1)]


decoder_tower:
    scale0 g0 
    # omit all but combiner for s,g=0,0
        #Cell(ex=6, k=5, g=0)
        #Cell(ex=6, k=5, g=0)
        #Cell(ex=6, k=5, g=0)
                Cell(combiner_dec)  # we do use the combiner, with z0/ftr0 as input
    scale0 g1
        Cell(ex=6, k=5, g=0)
        Cell(ex=6, k=5, g=0)
        Cell(ex=6, k=5, g=0)
                Cell(combiner_dec)

        Cell(ex=6, k=5, g=0, strides=-1)
        

    scale1 g0 
        Cell(ex=6, k=5, g=0)
        Cell(ex=6, k=5, g=0)
        Cell(ex=6, k=5, g=0)
                Cell(combiner_dec)
    scale1 g1
        Cell(ex=6, k=5, g=0)
        Cell(ex=6, k=5, g=0)
        Cell(ex=6, k=5, g=0)
                Cell(combiner_dec)

        #Cell(ex=6, k=5, g=0, strides=-1) # omit on last scale

post_process:
    block0
        Cell(ex=3, k=5, g=0, strides=-1)  (up_post)
        Cell(ex=3, k=5, g=0               (normal_post)
        Cell(ex=3, k=5, g=0               (normal_post)
    block
        Cell(ex=3, k=5, g=0, strides=-1)  (up_post)
        Cell(ex=3, k=5, g=0               (normal_post)
        Cell(ex=3, k=5, g=0               (normal_post)

img_conditional
    ELU()
    Conv2d_3x3(cin=num_channels_enc, cout=3)


#####
# Sampling from the NVLabs code... it's not obvious how to sample without the encoder side inputs
    def sample(self, num_samples, t):
        scale_ind = 0
        z0_size = [num_samples] + self.z0_size
        dist = Normal(mu=torch.zeros(z0_size).cuda(), log_sigma=torch.zeros(z0_size).cuda(), temp=t)
        z, _ = dist.sample()

        idx_dec = 0
        s = self.prior_ftr0.unsqueeze(0)
        batch_size = z.size(0)
        s = s.expand(batch_size, -1, -1, -1)
        for cell in self.dec_tower:
            if cell.cell_type == 'combiner_dec':
                if idx_dec > 0:
                    # form prior
                    param = self.dec_sampler[idx_dec - 1](s)
                    mu, log_sigma = torch.chunk(param, 2, dim=1)
                    dist = Normal(mu, log_sigma, t)
                    z, _ = dist.sample()

                # 'combiner_dec'
                s = cell(s, z)
                idx_dec += 1
            else:
                s = cell(s)
                if cell.cell_type == 'up_dec':
                    scale_ind += 1

        if self.vanilla_vae:
            s = self.stem_decoder(z)

        for cell in self.post_process:
            s = cell(s)

        logits = self.image_conditional(s)
        return logits
